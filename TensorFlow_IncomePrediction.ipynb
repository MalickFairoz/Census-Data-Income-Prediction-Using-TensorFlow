{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the census data using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display the head of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert the label column to 0s and 1s instead of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lable_fix(label):\n",
    "    if label == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(lable_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform the train test split on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket' , axis = 1)\n",
    "y_lables = census['income_bracket']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_lables, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create feature columns for categorical values using vocabulary lists or hash buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\" , [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\" , hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital_status\" , hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education\" ,hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create the feature columns for the continuous values using numeric_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Put all these variables into a single list with variable name feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [gender, occupation, marital_status, relationship, education, workclass, native_country, age, education_num, \n",
    "             capital_gain, capital_loss, hours_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create the input function with batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=x_train, y=y_train, batch_size=100, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create the model with tf.estimator using Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\malic\\AppData\\Local\\Temp\\tmprfey3xgg\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\malic\\\\AppData\\\\Local\\\\Temp\\\\tmprfey3xgg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002174AE95C88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train the model for atleast 5000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\malic\\AppData\\Local\\Temp\\tmprfey3xgg\\model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 76.409\n",
      "INFO:tensorflow:loss = 358.03915, step = 101 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.235\n",
      "INFO:tensorflow:loss = 343.34198, step = 201 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.585\n",
      "INFO:tensorflow:loss = 727.407, step = 301 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.558\n",
      "INFO:tensorflow:loss = 754.88605, step = 401 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.793\n",
      "INFO:tensorflow:loss = 983.00995, step = 501 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.785\n",
      "INFO:tensorflow:loss = 175.8079, step = 601 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.57\n",
      "INFO:tensorflow:loss = 93.3476, step = 701 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.531\n",
      "INFO:tensorflow:loss = 152.81537, step = 801 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.873\n",
      "INFO:tensorflow:loss = 208.61308, step = 901 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.231\n",
      "INFO:tensorflow:loss = 30.121696, step = 1001 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.09\n",
      "INFO:tensorflow:loss = 267.5742, step = 1101 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.119\n",
      "INFO:tensorflow:loss = 83.47671, step = 1201 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.194\n",
      "INFO:tensorflow:loss = 168.5289, step = 1301 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.205\n",
      "INFO:tensorflow:loss = 246.0497, step = 1401 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.3\n",
      "INFO:tensorflow:loss = 51.42318, step = 1501 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.425\n",
      "INFO:tensorflow:loss = 41.577934, step = 1601 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.809\n",
      "INFO:tensorflow:loss = 133.7385, step = 1701 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.784\n",
      "INFO:tensorflow:loss = 117.9079, step = 1801 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.596\n",
      "INFO:tensorflow:loss = 24.287941, step = 1901 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.335\n",
      "INFO:tensorflow:loss = 54.22103, step = 2001 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.447\n",
      "INFO:tensorflow:loss = 59.20203, step = 2101 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.672\n",
      "INFO:tensorflow:loss = 40.852444, step = 2201 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.582\n",
      "INFO:tensorflow:loss = 27.664999, step = 2301 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.684\n",
      "INFO:tensorflow:loss = 21.11027, step = 2401 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.718\n",
      "INFO:tensorflow:loss = 133.84962, step = 2501 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.835\n",
      "INFO:tensorflow:loss = 213.01767, step = 2601 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.369\n",
      "INFO:tensorflow:loss = 29.708626, step = 2701 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.007\n",
      "INFO:tensorflow:loss = 36.556625, step = 2801 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.008\n",
      "INFO:tensorflow:loss = 49.884438, step = 2901 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.558\n",
      "INFO:tensorflow:loss = 56.460537, step = 3001 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.754\n",
      "INFO:tensorflow:loss = 258.8515, step = 3101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.926\n",
      "INFO:tensorflow:loss = 69.9651, step = 3201 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.258\n",
      "INFO:tensorflow:loss = 35.572456, step = 3301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.74\n",
      "INFO:tensorflow:loss = 22.352816, step = 3401 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.053\n",
      "INFO:tensorflow:loss = 56.81018, step = 3501 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.849\n",
      "INFO:tensorflow:loss = 54.050392, step = 3601 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.287\n",
      "INFO:tensorflow:loss = 107.96275, step = 3701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.95\n",
      "INFO:tensorflow:loss = 31.378098, step = 3801 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.444\n",
      "INFO:tensorflow:loss = 296.51065, step = 3901 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.554\n",
      "INFO:tensorflow:loss = 36.25063, step = 4001 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.04\n",
      "INFO:tensorflow:loss = 107.75581, step = 4101 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.385\n",
      "INFO:tensorflow:loss = 76.23387, step = 4201 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.234\n",
      "INFO:tensorflow:loss = 42.268, step = 4301 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.96\n",
      "INFO:tensorflow:loss = 26.880184, step = 4401 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.143\n",
      "INFO:tensorflow:loss = 95.32377, step = 4501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.297\n",
      "INFO:tensorflow:loss = 63.44742, step = 4601 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.34\n",
      "INFO:tensorflow:loss = 51.992374, step = 4701 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.344\n",
      "INFO:tensorflow:loss = 33.065083, step = 4801 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.389\n",
      "INFO:tensorflow:loss = 55.56402, step = 4901 (0.490 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\malic\\AppData\\Local\\Temp\\tmprfey3xgg\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 31.139023.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x2174ae95e80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evalution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=x_test, batch_size=len(x_train), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\malic\\AppData\\Local\\Temp\\tmprfey3xgg\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Using model.predict() and passing the input function. \n",
    "# This will produce a generator of predictions, which can then transformed into list\n",
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([-0.75077933], dtype=float32),\n",
       " 'logistic': array([0.32065153], dtype=float32),\n",
       " 'probabilities': array([0.67934847, 0.3206515 ], dtype=float32),\n",
       " 'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each item in the list will look like this\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Create a list of class_ids key values from the prediction list of dictionaries. These prediction will be used to compare against y_test values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Calculating the model performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90      7436\n",
      "          1       0.69      0.69      0.69      2333\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
